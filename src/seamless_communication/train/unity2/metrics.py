# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

import math
from typing import Any, Dict, Optional, Sequence, Tuple, final
import torch
from torch import Tensor
from torch.nn import Module
from torcheval.metrics import Mean, Sum, Throughput
from fairseq2.gang import Gang
from fairseq2.metrics import MetricBag
from fairseq2.typing import override

from seamless_communication.models.unity.model import UnitYBatch

@final
class UnitYMetricBag(MetricBag):
    """Holds the common metrics of a UnitY model."""

    loss: Mean
    entropy_loss: Mean
    batch_size: Mean
    elements_per_batch: Mean
    elements_per_second: Throughput
    num_examples: Sum
    num_source_elements: Sum
    num_target_elements: Sum

    def __init__(self, gang: Gang) -> None:
        """
        :param gang:
            The gang to sync metrics across all processes.
        """
        super().__init__(gang)

        d = gang.device

        self.register_metric("loss", Mean(device=d), persistent=False)

        self.register_metric("entropy_loss", Mean(device=d), persistent=False)

        self.register_metric("batch_size", Mean(device=d), persistent=False)

        self.register_metric("elements_per_batch", Mean(device=d), persistent=False)

        self.register_metric("elements_per_second", Throughput(device=d), persistent=False)  # fmt: skip

        self.num_examples = Sum(device=d)

        self.num_source_elements = Sum(device=d)
        self.num_target_elements = Sum(device=d)

    def update_metrics(
        self,
        batches: Sequence[UnitYBatch],
        losses: Sequence[Tensor],
        elapsed_time: float,
    ) -> None:
        """Update the metrics.

        :param batches:
            The batches processed by the model in the last training step.
        :param output:
            The losses generated by the model for each batch in ``batches``.
        :param elapsed_time:
            The total elapsed time to read and process ``batches``.
        """
        loss = torch.zeros((), dtype=torch.float64)

        batch_size = torch.zeros((), dtype=torch.float64)

        num_source_elements = torch.zeros((), dtype=torch.float64)
        num_target_elements = torch.zeros((), dtype=torch.float64)

        for batch, batch_loss in zip(batches, losses):
            loss += float(batch_loss)

            batch_size += batch.batch_size

            num_source_elements += batch.num_source_elements()
            num_target_elements += batch.num_target_elements() - batch.batch_size

        loss /= num_target_elements

        self.loss.update(loss, weight=num_target_elements)

        # Mainly exists for compatibility with fairseq's `nll_loss`.
        self.entropy_loss.update(loss / math.log(2), weight=num_target_elements)

        self.batch_size.update(batch_size * self.gang.size)

        self.elements_per_batch.update(num_target_elements * self.gang.size)

        self.elements_per_second.update(int(num_target_elements), elapsed_time)

        self.num_examples.update(batch_size)

        self.num_source_elements.update(num_source_elements)
        self.num_target_elements.update(num_target_elements)

    def reset_batch_metrics(self) -> None:
        """Reset the batch metrics to their initial state."""
        self.loss.reset()
        self.entropy_loss.reset()
        self.batch_size.reset()
        self.elements_per_batch.reset()
        self.elements_per_second.reset()

    @override
    def process_metric_values(self, values: Dict[str, Any]) -> None:
        values["elapsed_time"] = self.elements_per_second.elapsed_time_sec
